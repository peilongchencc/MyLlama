# 模型训练相关基础

## LoRA微调后，合并参数在预测之后，还是预测之前？

这主要取决于你预测(推理)的方式:

如果你采用的是使用的是一个单独的 LoRA 适配器，并没有将 LoRA 参数直接合并到基础模型中。

这意味着在推理过程中，模型将基础模型与 LoRA 适配器结合使用，而不是将 LoRA 参数合并到模型权重中并生成一个新的模型文件‼️‼️

这种方式的优点是灵活性高，因为你可以在不同的任务或场景中使用不同的适配器，而无需每次都重新训练或保存一个新的完整模型。

🚨缺点：每次推理时都需要加载基础模型和适配器，这可能会影响推理的速度或增加显存的需求，尽管通常相对快速，但还是会有一些影响。


## 多任务学习和多标签任务的区别:

多任务学习（Multi-Task Learning, MTL）和多标签任务（Multi-Label Task, ML）是机器学习中的两个不同概念，但它们都涉及处理多个目标或输出。以下是它们的区别：

### 1. 多任务学习 (Multi-Task Learning, MTL)

多任务学习是一种同时学习多个相关任务的机器学习方法。这些任务通常共享一些信息或表示，因此可以通过共享模型的某些部分（如网络层、参数）来提高每个任务的性能。多任务学习的目标是通过同时学习多个任务来提高每个任务的泛化能力。具体来说：

- 任务数量：涉及多个不同的任务，每个任务有自己的目标（如分类、回归、序列预测等）。
- 输出：每个任务都有自己的独立输出。
- 共享表示：多个任务共享相同的模型部分（如神经网络中的某些层），以便利用任务间的相关性。
- 应用场景：如在计算机视觉中同时进行图像分类和对象检测，或在自然语言处理（NLP）中同时进行情感分析和主题分类。

### 2. 多标签任务 (Multi-Label Task, ML)

多标签任务指的是一种机器学习问题，其中一个输入样本可以同时属于多个标签类别。与传统的单标签分类不同，多标签任务的输出不是单个类别，而是多个类别的集合。具体来说：

- 任务数量：涉及单一任务，但这个任务要求对每个样本预测多个标签。
- 输出：每个样本对应多个可能的标签输出（例如，[0, 1, 1, 0] 表示样本属于第二和第三类）。
- 独立性：标签之间通常是相互独立的，尽管在某些情况下，标签之间可能存在关联性。
- 应用场景：如文本分类中的多标签分类任务，一个新闻文章可以同时标注为“体育”、“经济”和“政治”；在音乐分类中，一首歌可以同时标记为“摇滚”和“流行”。

### 总结

- 多任务学习处理的是多个不同的任务，目标是利用任务间的相关性来提升各个任务的表现。
- 多标签任务处理的是一个任务中同时预测多个标签，标签之间通常是独立的。